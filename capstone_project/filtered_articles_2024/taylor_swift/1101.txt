Taylor Swift is usually going viral for one reason or another, whether it’s for being the subject of political conspiracies, stealing the show at NFL games, or for dominating the stage on The Eras Tour. Recently, though, Swift got a lot of attention online for a reason that’s more upsetting.
First, a bit of background. Starting in late 2022, AI technologies like ChatGPT took off in a big way, when they started getting widespread use at a consumer level. Other tools popped up from there, including some that could generate realistic-looking images.
Well, recently, some people (it’s not currently clear who) used AI-powered image utilities to create what looked like NSFW photographs of Swift nude and/or participating in explicit sexual acts. The images spread as they were shared on X (formerly Twitter) and they started to go viral on January 24.
As NBC News reports, the images racked up “over 27 million views and more than 260,000 likes in 19 hours before the account that posted the images was suspended.” The publication also notes, “The most viewed and shared deepfakes of Swift portrayed her nude in a football stadium,” in reference to her relationship with Travis Kelce and frequent presence at Kansas City Chiefs games.
X took an additional measure in an attempt to limit the exposure of the images: Currently, searching for “Taylor Swift” on X yields an error message and no results.
SAG-AFTRA shared a statement in support of Swift, saying in part, “The development and dissemination of fake images — especially those of a lewd nature — without someone’s consent must be made illegal. As a society, we have it in our power to control these technologies, but we must act now before it is too late.”
One reaction people had to this saga is to wonder about laws pertaining to this sort of use of AI technology. As Variety reports, at a White House press briefing on January 26, a reporter asked if President Joe Biden supported legislation banning pornographic, AI-generated images. White House press secretary Karine Jean-Pierre responded, “It is alarming. We are alarmed by the reports of the circulation of images that you just laid out… There should be legislation, obviously, to deal with this issue.”
The wheels are already in motion on that front: In 2023, New York Representative Joe Morelle introduced the Preventing Deepfakes of Intimate Images Act (per Variety). SAG-AFTRA Fran Drescher expressed her support at the time, saying, “Sexual abuse, whether occurring physically or digitally, should never be excused or permitted as ‘personal expression,’ and it should never be tolerated.”
Swift herself has yet to publicly address the situation, but it has been reported that she is considering legal action.