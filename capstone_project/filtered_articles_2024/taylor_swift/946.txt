Manage your account
Social media users may have noticed Saturday that they cannot search Taylor Swift’s name on X, days after nonconsensual sexually explicit deepfakes of the pop star went viral.
Whenever Swift’s name was typed into the search box on X, the message “Something went wrong. Try reloading” would appear.
NBC News has reached out to X for comment.
This comes after deepfakes portraying Swift nude and in sexual scenarios were circulated on X Wednesday. The images can be created using artificial intelligence tools that develop new, fake images, or by taking a real photo and “undressing” it.
It’s not clear where the images originated, but they included a watermark that suggests they came from a website that is known for publishing fake nude images of celebrities. The website has a section dedicated to “AI deepfake.”
The photos were viewed more than 27 million times and had more than 260,000 likes in 19 hours before the account that posted them was suspended.
Many of Swift’s fans said the deepfakes were removed because of a mass-reporting campaign. X has been called out in the past for its failure to quickly address sexually explicit deepfakes that pop up on the site.
The singer’s fans flooded the hashtag “Taylor Swift AI” with positive messages about her, according to an analysis performed by Blackbird.AI, a firm that works to protect organizations from narrative-driven online attacks using AI technology. The hashtag “Protect Taylor Swift” also began to trend on X.
Some users celebrated Swift’s name being removed from X’s search function. One user wrote that it was the “first step done to safeguard her.”
“Now stop searching taylor swift ai photos. That AI creator will go to hell. We have got ur back Tay,” the user posted Saturday.
“You can’t search Taylor swift on Twitter anymore kinda happy and sad at the same time,” another posted.
This article was originally published on NBCNews.com