Meta's decision to train its AI using publicly available photos from Instagram has sparked an exodus of artists from the platform who feel uncomfortable by this policy change. However, users in the US, UK, and Europe can actually opt out of this program.
Instagram has been a haven for artists of all styles to showcase their work and cultivate a following for years. However, an alarming number of users are abandoning the platform to protest Meta's policy that utilises publicly posted art to train its AI models.
The artists' exodus can be attributed to two key events. In May, a Meta executive sparked outrage by announcing that publicly shared Instagram posts would be used to train the company's AI models.
This was followed by notifications sent to European users just weeks later, informing them that their content would be used for AI development starting June 26, with no option to opt out. While some regions, like the EU, provide mechanisms to challenge Meta's data practices, many artists feel a growing sense of disempowerment.
Many artists feel trapped on Instagram. While it provides crucial exposure, they fear their work is being used to train AI models that could eventually replace them. This concern isn't new for creative fields.
Artists, musicians, and authors have previously filed lawsuits against companies like Google and Stability AI, arguing that their training data infringes on copyrights. In April, over 200 prominent musicians, including superstars like Billie Eilish and Nicki Minaj, signed an open letter condemning the predatory use of artificial intelligence (AI) that imitates human creativity in music.
AI companies counter these claims with "fair use" arguments, asserting their work is transformative.
Artists frustrated by Instagram's policies are exploring new platforms. Cara, a free portfolio app launched in January 2023, has become a popular alternative despite some issues. This artist-centric platform offers a familiar interface reminiscent of Instagram but with a key difference: AI-generated art is prohibited.
Additionally, Cara utilises technology to deter data scraping, which is a concern for artists who are worried about their work being used to train AI. Data scraping from the internet has become a significant battleground in the development of AI.
In 2019, a security vulnerability allowed hackers to scrape data from over 533 million Facebook user accounts. Tech companies contend that publicly available online content falls under "fair use" and can be used for training AI models.
However, this practice is increasingly challenged by lawsuits contesting copyright infringement. Establishing clear regulations for data scraping in the AI space is likely a long way to go. For Meta, publicly available posts are a treasure trove of information. But fear not; options are still available if you're uncomfortable with Meta using your content and don't want to switch platforms like Cara.
Unfortunately, users in the US, along with those in countries lacking national data privacy laws, have limited options to prevent Meta from using their publicly shared content for AI training. Meta's already incorporated such data into its models. Additionally, there's no built-in opt-out option for these regions.
A spokesperson for Meta assured users that private message content is not included in their AI training data. However, publicly shared posts on social media are considered fair game for anyone to use, including Meta for AI development. If you're uncomfortable with this, you can minimise the risk by setting your account to private.
According to the spokesperson, Meta offers built-in tools for users to delete personal information from conversations with Meta AI.
Thankfully, users in the European Union and the UK benefit from strong data protection laws. This grants them the right to object to their data being used for training purposes. As a result, opting out is a more achievable option for them.
Meta, responding to a request from Ireland's Data Protection Commission (DPC), has reluctantly paused its plans to leverage user data for AI training.
"We're disappointed by the request from the Irish Data Protection Commission (DPC), our lead regulator, on behalf of the European DPAs, to delay training our large language models (LLMs) using public content shared by adults on Facebook and Instagram — particularly since we incorporated regulatory feedback and the European DPAs have been informed since March."
"This is a step backwards for European innovation, competition in AI development and further delays bringing the benefits of AI to people in Europe," Stefano Fratta, Global Engagement Director, Meta Privacy Policy wrote in a blog post.
© Copyright IBTimes 2025. All rights reserved.