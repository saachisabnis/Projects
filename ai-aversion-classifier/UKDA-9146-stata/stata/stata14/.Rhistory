###### **Step 5: Manual Cross-Validation to Find Best Lambda** ######
lambda_vals <-  lambda_vals <- seq(0, 0.5, by = 0.01) # Define search range for lambda
lambda_loss <- numeric(length(lambda_vals))
K <- 10  # Number of folds for cross-validation
for (i in seq_along(lambda_vals)) {
lambda <- lambda_vals[i]
fold_id <- sample(rep(1:K, length.out = nrow(X_train)))
total_loss <- 0
for (k in 1:K) {
val_X <- X_train[fold_id == k, , drop = FALSE]
train_X <- X_train[fold_id != k, , drop = FALSE]
val_y <- y_train[fold_id == k]
train_y <- y_train[fold_id != k]
k_mod <- glmnet(train_X, train_y, family = "binomial", lambda = lambda, alpha = 1)
yhat_k <- predict(k_mod, newx = val_X, type = "response")
yhat_k <- pmax(1e-10, pmin(1 - 1e-10, yhat_k))   # Prevent log(0)
k_loss <- -sum(log((yhat_k^val_y) * ((1 - yhat_k)^(1 - val_y)))) # Binary cross-entropy loss
total_loss <- total_loss + k_loss
}
lambda_loss[i] <- total_loss / K
}
best_lambda <- lambda_vals[which.min(lambda_loss)]  # Select best lambda
###### **Step 6: Train Model and Adjust for Overfitting** ######
overfit_check <- TRUE
iteration <- 0
while (overfit_check && iteration < 10) {
final_lasso <- glmnet(X_train, y_train, family = "binomial", lambda = best_lambda, alpha = 1)
coef_glmnet <- coef(final_lasso)
selected_features <- which(coef_glmnet[-1] != 0)
feature_names <- colnames(X_train)[selected_features]
# **Check if Overfitting (if Training AUC Too High)**
y_train_pred_prob <- predict(final_lasso, newx = as.matrix(X_train), type = "response")[, 1]
auc_train <- suppressMessages(auc(factor(y_train, levels = c(0,1)), y_train_pred_prob))
if (auc_train > 0.95) {
best_lambda <- best_lambda * 1.3 # Increase lambda to prevent overfitting
} else {
overfit_check <- FALSE
}
iteration <- iteration + 1
}
# Final selected features
X_final_train <- X_train[, selected_features]
X_final_test <- X_test[, selected_features]
# Train final model using Elastic Net (alpha = 0.5)
final_model <- glmnet(X_final_train, y_train, family = "binomial", lambda = best_lambda, alpha = 0.5)
cat("Selected features:\n", colnames(X_final_train), "\n")
###### **Step 7: Model Evaluation on Out of Sample Data** ######
y_pred_prob <- predict(final_model, newx = as.matrix(X_final_test), type = "response")[, 1]
# **Compute AUC on Test Set**
auc_value <- suppressMessages(auc(factor(y_test, levels = c(0, 1)), y_pred_prob))
# Compute binary cross-entropy loss
bce_loss <- -sum(log((y_pred_prob^y_test) * ((1 - y_pred_prob)^(1 - y_test)))) / length(y_test)
cat("Binary Cross-Entropy Loss:", bce_loss, "\n")
cat("AUC:", auc_value, "\n")
# Generate and plot ROC curve
roc_curve <- rocit(score = y_pred_prob, class = y_test)
plot(roc_curve, col = "blue", lwd = 2, legend = TRUE, main = "ROC Curve for LASSO Model")
abline(a = 0, b = 1, lty = 2, col = "gray") # Add random classifier reference line
return(final_model)
}
# For reproducibility
# Set seed for reproducibility
set.seed(123)
# Number of observations (adjustable)
n <- 250  # Slightly increased sample size
# Generate 20 continuous predictor variables with a different distribution
X_new <- as.data.frame(matrix(rnorm(n * 20, mean = 1, sd = 1.2), nrow = n, ncol = 20))
colnames(X_new) <- paste0("X", 1:20)
# Define true coefficients with some non-zero values beyond the first 3 variables
true_coeffs_new <- c(2, -1.5, 0.5, 1.8, -0.7, 0.3, rep(0, 14))
# Generate linear combination with some noise
linear_part_new <- as.matrix(X_new) %*% true_coeffs_new + rnorm(n, mean = 0, sd = 1.3)
# Convert to probabilities using a logistic function
prob_y_new <- 1 / (1 + exp(-linear_part_new))  # Sigmoid function
# Generate binary outcome variable y using the probabilities
y_new <- rbinom(n, 1, prob_y_new)
# Shuffle the dataset to avoid any structured order
shuffle_idx <- sample(1:n, n)
X_new <- X_new[shuffle_idx, ]
y_new <- y_new[shuffle_idx]
# Add a small amount of random noise to some features to simulate slight real-world variations
X_new[, 5:10] <- X_new[, 5:10] + rnorm(n, mean = 0, sd = 0.5)
# Now you can test your function with the new data
find_rmod(X_new, y_new)
find_rmod <- function(X, y) {
#install.packages("glmnet").
#install.packages("pROC")
#install.packages("ROCit")
#install.packages("car")
#install.packages("caret")
# Load required libraries
library(glmnet)
library(pROC)
library(ROCit)
library(car)
library(caret)
###### **Step 1: Unit Testing - Ensuring Clean Data** ######
# Ensure X is a dataframe
if (!is.data.frame(X)) {
stop("Error: X must be a dataframe.")
}
# Ensure y is a vector
if (!is.vector(y) || is.matrix(y)) {
stop("Error: y must be a numeric vector.")
}
# Ensure X has at least 20 columns
if (ncol(X) < 20) {
stop("Error: X must have at least 20 predictor variables.")
}
# Ensure X and y have the same number of rows
if (nrow(X) != length(y)) {
stop("Error: X and y must have the same number of observations.")
}
# **Checking for Missing Values (NA)**
if (any(is.na(X)) || any(is.na(y))) {
na_rows <- apply(X, 1, function(row) any(is.na(row)))
X <- X[!na_rows, ]
y <- y[!na_rows]
}
# **Ensuring that y is a Binary Value**
if (length(unique(y)) > 2) {
y <- as.numeric(y > median(y))
}
# **Ensuring X is Numeric and Continuous**
X <- data.frame(lapply(X, function(col) {
if (!is.numeric(col)) {
as.numeric(as.factor(col))
} else {
col
}
}))
# **Standardizing X values to ensure values are on the same scale**
X_scaled <- scale(X)
###### **Step 2: Feature Engineering (Interactions and Polynomials)** ######
# **Generating 2 Way Interaction Terms for all X Variables**
interaction_terms <- model.matrix(~(.)^2, data = as.data.frame(X_scaled))[, -1]
# *Generating Polynomial Terms (Up to 7th Order)**
poly_order <- 7
poly_terms_list <- lapply(1:ncol(X_scaled), function(i) poly(X_scaled[, i], poly_order, raw = TRUE))
poly_terms <- do.call(cbind, poly_terms_list)
# **Combining Interaction and Polynomial Terms into one dataset**
X_expanded <- cbind(interaction_terms, poly_terms)
# **Assigning Meaningful Column Names**
colnames(X_expanded) <- c(
colnames(interaction_terms),
unlist(lapply(1:ncol(X_scaled), function(i) paste0("X", i, "_poly", 1:poly_order)))
)
###### **Step 3: Feature Selection (Reduce Feature Space To Avoid Overfitting)** ######
# Compute correlation of each feature with y
feature_cor <- apply(X_expanded, 2, function(col) abs(cor(col, y, use = "complete.obs")))
# Select the top 100 most predictive features
selected_features <- names(sort(feature_cor, decreasing = TRUE)[1:100])
# Retain only the selected features
X_expanded <- X_expanded[, selected_features]
###### **Step 4: Train-Test Split (80-20%)** ######
set.seed(42)
train_idx <- sample(seq_len(nrow(X_expanded)), size = 0.8 * nrow(X_expanded))
X_train <- X_expanded[train_idx, ]
X_test <- X_expanded[-train_idx, ]
y_train <- y[train_idx]
y_test <- y[-train_idx]
###### **Step 5: Manual Cross-Validation to Find Best Lambda** ######
lambda_vals <-  lambda_vals <- seq(0, 0.5, by = 0.01) # Define search range for lambda
lambda_loss <- numeric(length(lambda_vals))
K <- 10  # Number of folds for cross-validation
for (i in seq_along(lambda_vals)) {
lambda <- lambda_vals[i]
fold_id <- sample(rep(1:K, length.out = nrow(X_train)))
total_loss <- 0
for (k in 1:K) {
val_X <- X_train[fold_id == k, , drop = FALSE]
train_X <- X_train[fold_id != k, , drop = FALSE]
val_y <- y_train[fold_id == k]
train_y <- y_train[fold_id != k]
k_mod <- glmnet(train_X, train_y, family = "binomial", lambda = lambda, alpha = 1)
yhat_k <- predict(k_mod, newx = val_X, type = "response")
yhat_k <- pmax(1e-10, pmin(1 - 1e-10, yhat_k))   # Prevent log(0)
k_loss <- -sum(log((yhat_k^val_y) * ((1 - yhat_k)^(1 - val_y)))) # Binary cross-entropy loss
total_loss <- total_loss + k_loss
}
lambda_loss[i] <- total_loss / K
}
best_lambda <- lambda_vals[which.min(lambda_loss)]  # Select best lambda
###### **Step 6: Train Model and Adjust for Overfitting** ######
overfit_check <- TRUE
iteration <- 0
while (overfit_check && iteration < 10) {
final_lasso <- glmnet(X_train, y_train, family = "binomial", lambda = best_lambda, alpha = 1)
coef_glmnet <- coef(final_lasso)
selected_features <- which(coef_glmnet[-1] != 0)
feature_names <- colnames(X_train)[selected_features]
# **Check if Overfitting (if Training AUC Too High)**
y_train_pred_prob <- predict(final_lasso, newx = as.matrix(X_train), type = "response")[, 1]
auc_train <- suppressMessages(auc(factor(y_train, levels = c(0,1)), y_train_pred_prob))
if (auc_train > 0.95) {
best_lambda <- best_lambda * 1.3 # Increase lambda to prevent overfitting
} else {
overfit_check <- FALSE
}
iteration <- iteration + 1
}
# Final selected features
X_final_train <- X_train[, selected_features]
X_final_test <- X_test[, selected_features]
# Train final model using Elastic Net (alpha = 0.5)
final_model <- glmnet(X_final_train, y_train, family = "binomial", lambda = best_lambda, alpha = 0.5)
cat("Selected features:\n", colnames(X_final_train), "\n")
###### **Step 7: Model Evaluation on Out of Sample Data** ######
y_pred_prob <- predict(final_model, newx = as.matrix(X_final_test), type = "response")[, 1]
# **Compute AUC on Test Set**
auc_value <- suppressMessages(auc(factor(y_test, levels = c(0, 1)), y_pred_prob))
# Compute binary cross-entropy loss
bce_loss <- -sum(log((y_pred_prob^y_test) * ((1 - y_pred_prob)^(1 - y_test)))) / length(y_test)
cat("Binary Cross-Entropy Loss:", bce_loss, "\n")
cat("AUC:", auc_value, "\n")
# Generate and plot ROC curve
roc_curve <- rocit(score = y_pred_prob, class = y_test)
plot(roc_curve, col = "blue", lwd = 2, legend = TRUE, main = "ROC Curve for LASSO Model")
abline(a = 0, b = 1, lty = 2, col = "gray") # Add random classifier reference line
return(final_model)
}
cat("Binary Cross-Entropy Loss:", bce_loss, "\n")
cat("Binary Cross-Entropy Loss:", bce_loss, "\n")
find_rmod <- function(X, y) {
#install.packages("glmnet").
#install.packages("pROC")
#install.packages("ROCit")
#install.packages("car")
#install.packages("caret")
# Load required libraries
library(glmnet)
library(pROC)
library(ROCit)
library(car)
library(caret)
###### **Step 1: Unit Testing - Ensuring Clean Data** ######
# Ensure X is a dataframe
if (!is.data.frame(X)) {
stop("Error: X must be a dataframe.")
}
# Ensure y is a vector
if (!is.vector(y) || is.matrix(y)) {
stop("Error: y must be a numeric vector.")
}
# Ensure X has at least 20 columns
if (ncol(X) < 20) {
stop("Error: X must have at least 20 predictor variables.")
}
# Ensure X and y have the same number of rows
if (nrow(X) != length(y)) {
stop("Error: X and y must have the same number of observations.")
}
# **Checking for Missing Values (NA)**
if (any(is.na(X)) || any(is.na(y))) {
na_rows <- apply(X, 1, function(row) any(is.na(row)))
X <- X[!na_rows, ]
y <- y[!na_rows]
}
# **Ensuring that y is a Binary Value**
if (length(unique(y)) > 2) {
y <- as.numeric(y > median(y))
}
# **Ensuring X is Numeric and Continuous**
X <- data.frame(lapply(X, function(col) {
if (!is.numeric(col)) {
as.numeric(as.factor(col))
} else {
col
}
}))
# **Standardizing X values to ensure values are on the same scale**
X_scaled <- scale(X)
###### **Step 2: Feature Engineering (Interactions and Polynomials)** ######
# **Generating 2 Way Interaction Terms for all X Variables**
interaction_terms <- model.matrix(~(.)^2, data = as.data.frame(X_scaled))[, -1]
# *Generating Polynomial Terms (Up to 7th Order)**
poly_order <- 7
poly_terms_list <- lapply(1:ncol(X_scaled), function(i) poly(X_scaled[, i], poly_order, raw = TRUE))
poly_terms <- do.call(cbind, poly_terms_list)
# **Combining Interaction and Polynomial Terms into one dataset**
X_expanded <- cbind(interaction_terms, poly_terms)
# **Assigning Meaningful Column Names**
colnames(X_expanded) <- c(
colnames(interaction_terms),
unlist(lapply(1:ncol(X_scaled), function(i) paste0("X", i, "_poly", 1:poly_order)))
)
###### **Step 3: Feature Selection (Reduce Feature Space To Avoid Overfitting)** ######
# Compute correlation of each feature with y
feature_cor <- apply(X_expanded, 2, function(col) abs(cor(col, y, use = "complete.obs")))
# Select the top 100 most predictive features
selected_features <- names(sort(feature_cor, decreasing = TRUE)[1:100])
# Retain only the selected features
X_expanded <- X_expanded[, selected_features]
###### **Step 4: Train-Test Split (80-20%)** ######
set.seed(42)
train_idx <- sample(seq_len(nrow(X_expanded)), size = 0.8 * nrow(X_expanded))
X_train <- X_expanded[train_idx, ]
X_test <- X_expanded[-train_idx, ]
y_train <- y[train_idx]
y_test <- y[-train_idx]
###### **Step 5: Manual Cross-Validation to Find Best Lambda** ######
lambda_vals <-  lambda_vals <- seq(0, 0.5, by = 0.01) # Define search range for lambda
lambda_loss <- numeric(length(lambda_vals))
K <- 10  # Number of folds for cross-validation
for (i in seq_along(lambda_vals)) {
lambda <- lambda_vals[i]
fold_id <- sample(rep(1:K, length.out = nrow(X_train)))
total_loss <- 0
for (k in 1:K) {
val_X <- X_train[fold_id == k, , drop = FALSE]
train_X <- X_train[fold_id != k, , drop = FALSE]
val_y <- y_train[fold_id == k]
train_y <- y_train[fold_id != k]
k_mod <- glmnet(train_X, train_y, family = "binomial", lambda = lambda, alpha = 1)
yhat_k <- predict(k_mod, newx = val_X, type = "response")
yhat_k <- pmax(1e-10, pmin(1 - 1e-10, yhat_k))   # Prevent log(0)
k_loss <- -sum(log((yhat_k^val_y) * ((1 - yhat_k)^(1 - val_y)))) # Binary cross-entropy loss
total_loss <- total_loss + k_loss
}
lambda_loss[i] <- total_loss / K
}
best_lambda <- lambda_vals[which.min(lambda_loss)]  # Select best lambda
###### **Step 6: Train Model and Adjust for Overfitting** ######
overfit_check <- TRUE
iteration <- 0
while (overfit_check && iteration < 10) {
final_lasso <- glmnet(X_train, y_train, family = "binomial", lambda = best_lambda, alpha = 1)
coef_glmnet <- coef(final_lasso)
selected_features <- which(coef_glmnet[-1] != 0)
feature_names <- colnames(X_train)[selected_features]
# **Check if Overfitting (if Training AUC Too High)**
y_train_pred_prob <- predict(final_lasso, newx = as.matrix(X_train), type = "response")[, 1]
auc_train <- suppressMessages(auc(factor(y_train, levels = c(0,1)), y_train_pred_prob))
if (auc_train > 0.95) {
best_lambda <- best_lambda * 1.3 # Increase lambda to prevent overfitting
} else {
overfit_check <- FALSE
}
iteration <- iteration + 1
}
# Final selected features
X_final_train <- X_train[, selected_features]
X_final_test <- X_test[, selected_features]
# Train final model using Elastic Net (alpha = 0.5)
final_model <- glmnet(X_final_train, y_train, family = "binomial", lambda = best_lambda, alpha = 0.5)
cat("Selected features:\n", colnames(X_final_train), "\n")
###### **Step 7: Model Evaluation on Out of Sample Data** ######
y_pred_prob <- predict(final_model, newx = as.matrix(X_final_test), type = "response")[, 1]
# **Compute AUC on Test Set**
auc_value <- suppressMessages(auc(factor(y_test, levels = c(0, 1)), y_pred_prob))
# Compute binary cross-entropy loss
bce_loss <- -sum(log((y_pred_prob^y_test) * ((1 - y_pred_prob)^(1 - y_test)))) / length(y_test)
cat("Binary Cross-Entropy Loss:", bce_loss, "\n")
cat("AUC:", auc_value, "\n")
return(final_model)
}
# Set seed for reproducibility
set.seed(789)
# Number of observations (adjustable)
n_new <- 275  # Slightly different sample size
# Generate 20 continuous predictor variables with a different distribution
X_new2 <- as.data.frame(matrix(rnorm(n_new * 20, mean = 0.8, sd = 1.3), nrow = n_new, ncol = 20))
colnames(X_new2) <- paste0("X", 1:20)
# Define new true coefficients, ensuring different feature importance
true_coeffs_new2 <- c(1.7, -1.2, 0.6, 1.9, -0.5, 0.2, 1.0, -0.8, rep(0, 12))
# Generate linear combination with added noise
linear_part_new2 <- as.matrix(X_new2) %*% true_coeffs_new2 + rnorm(n_new, mean = 0, sd = 1.4)
# Convert to probabilities using a logistic function
prob_y_new2 <- 1 / (1 + exp(-linear_part_new2))  # Sigmoid function
# Generate binary outcome variable y using the probabilities
y_new2 <- rbinom(n_new, 1, prob_y_new2)
# Shuffle the dataset to avoid any structured order
shuffle_idx <- sample(1:n_new, n_new)
X_new2 <- X_new2[shuffle_idx, ]
y_new2 <- y_new2[shuffle_idx]
# Add a small amount of random noise to different features
X_new2[, 3:9] <- X_new2[, 3:9] + rnorm(n_new, mean = 0, sd = 0.4)
# Now you can test your function with the new dataset
find_rmod(X_new2, y_new2)
find_rmod <- function(X, y) {
#install.packages("glmnet").
#install.packages("pROC")
#install.packages("ROCit")
#install.packages("car")
#install.packages("caret")
# Load required libraries
library(glmnet)
library(pROC)
library(ROCit)
library(car)
library(caret)
###### **Step 1: Unit Testing - Ensuring Clean Data** ######
# Ensure X is a dataframe
if (!is.data.frame(X)) {
stop("Error: X must be a dataframe.")
}
# Ensure y is a vector
if (!is.vector(y) || is.matrix(y)) {
stop("Error: y must be a numeric vector.")
}
# Ensure X has at least 20 columns
if (ncol(X) < 20) {
stop("Error: X must have at least 20 predictor variables.")
}
# Ensure X and y have the same number of rows
if (nrow(X) != length(y)) {
stop("Error: X and y must have the same number of observations.")
}
# **Checking for Missing Values (NA)**
if (any(is.na(X)) || any(is.na(y))) {
na_rows <- apply(X, 1, function(row) any(is.na(row)))
X <- X[!na_rows, ]
y <- y[!na_rows]
}
# **Ensuring that y is a Binary Value**
if (length(unique(y)) > 2) {
y <- as.numeric(y > median(y))
}
# **Ensuring X is Numeric and Continuous**
X <- data.frame(lapply(X, function(col) {
if (!is.numeric(col)) {
as.numeric(as.factor(col))
} else {
col
}
}))
# **Standardizing X values to ensure values are on the same scale**
X_scaled <- scale(X)
###### **Step 2: Feature Engineering (Interactions and Polynomials)** ######
# **Generating 2 Way Interaction Terms for all X Variables**
interaction_terms <- model.matrix(~(.)^2, data = as.data.frame(X_scaled))[, -1]
# *Generating Polynomial Terms (Up to 7th Order)**
poly_order <- 7
poly_terms_list <- lapply(1:ncol(X_scaled), function(i) poly(X_scaled[, i], poly_order, raw = TRUE))
poly_terms <- do.call(cbind, poly_terms_list)
# **Combining Interaction and Polynomial Terms into one dataset**
X_expanded <- cbind(interaction_terms, poly_terms)
# **Assigning Meaningful Column Names**
colnames(X_expanded) <- c(
colnames(interaction_terms),
unlist(lapply(1:ncol(X_scaled), function(i) paste0("X", i, "_poly", 1:poly_order)))
)
###### **Step 3: Feature Selection (Reduce Feature Space To Avoid Overfitting)** ######
# Compute correlation of each feature with y
feature_cor <- apply(X_expanded, 2, function(col) abs(cor(col, y, use = "complete.obs")))
# Select the top 100 most predictive features
selected_features <- names(sort(feature_cor, decreasing = TRUE)[1:100])
# Retain only the selected features
X_expanded <- X_expanded[, selected_features]
###### **Step 4: Train-Test Split (80-20%)** ######
set.seed(42)
train_idx <- sample(seq_len(nrow(X_expanded)), size = 0.8 * nrow(X_expanded))
X_train <- X_expanded[train_idx, ]
X_test <- X_expanded[-train_idx, ]
y_train <- y[train_idx]
y_test <- y[-train_idx]
###### **Step 5: Manual Cross-Validation to Find Best Lambda** ######
lambda_vals <-  lambda_vals <- seq(0, 0.5, by = 0.01) # Define search range for lambda
lambda_loss <- numeric(length(lambda_vals))
K <- 10  # Number of folds for cross-validation
for (i in seq_along(lambda_vals)) {
lambda <- lambda_vals[i]
fold_id <- sample(rep(1:K, length.out = nrow(X_train)))
total_loss <- 0
for (k in 1:K) {
val_X <- X_train[fold_id == k, , drop = FALSE]
train_X <- X_train[fold_id != k, , drop = FALSE]
val_y <- y_train[fold_id == k]
train_y <- y_train[fold_id != k]
k_mod <- glmnet(train_X, train_y, family = "binomial", lambda = lambda, alpha = 1)
yhat_k <- predict(k_mod, newx = val_X, type = "response")
yhat_k <- pmax(1e-10, pmin(1 - 1e-10, yhat_k))   # Prevent log(0)
k_loss <- -sum(log((yhat_k^val_y) * ((1 - yhat_k)^(1 - val_y)))) # Binary cross-entropy loss
total_loss <- total_loss + k_loss
}
lambda_loss[i] <- total_loss / K
}
best_lambda <- lambda_vals[which.min(lambda_loss)]  # Select best lambda
###### **Step 6: Train Model and Adjust for Overfitting** ######
overfit_check <- TRUE
iteration <- 0
while (overfit_check && iteration < 10) {
final_lasso <- glmnet(X_train, y_train, family = "binomial", lambda = best_lambda, alpha = 1)
coef_glmnet <- coef(final_lasso)
selected_features <- which(coef_glmnet[-1] != 0)
feature_names <- colnames(X_train)[selected_features]
# **Check if Overfitting (if Training AUC Too High)**
y_train_pred_prob <- predict(final_lasso, newx = as.matrix(X_train), type = "response")[, 1]
auc_train <- suppressMessages(auc(factor(y_train, levels = c(0,1)), y_train_pred_prob))
if (auc_train > 0.95) {
best_lambda <- best_lambda * 1.3 # Increase lambda to prevent overfitting
} else {
overfit_check <- FALSE
}
iteration <- iteration + 1
}
# Final selected features
X_final_train <- X_train[, selected_features]
X_final_test <- X_test[, selected_features]
# Train final model using Elastic Net (alpha = 0.5)
final_model <- glmnet(X_final_train, y_train, family = "binomial", lambda = best_lambda, alpha = 0.5)
cat("Selected features:\n", colnames(X_final_train), "\n")
###### **Step 7: Model Evaluation on Out of Sample Data** ######
y_pred_prob <- predict(final_model, newx = as.matrix(X_final_test), type = "response")[, 1]
# **Compute AUC on Test Set**
auc_value <- suppressMessages(auc(factor(y_test, levels = c(0, 1)), y_pred_prob))
# Compute binary cross-entropy loss
bce_loss <- -sum(log((y_pred_prob^y_test) * ((1 - y_pred_prob)^(1 - y_test)))) / length(y_test)
cat("Binary Cross-Entropy Loss:", bce_loss, "\n")
cat("AUC:", auc_value, "\n")
return(final_model)
}
